{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ijT4ueHNfiMW",
        "3VsAsjPZfiMZ",
        "sXsod2oqfiMd",
        "LfLez57kfiMg"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT0XbCf9f3hR",
        "outputId": "d90af64c-1126-4d97-c69c-b3c443f8fd52"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rdw230SfiKz",
        "outputId": "613bb4a7-adea-4d75-e10c-a59d5401cbbe"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbQmgFHmfiLn",
        "outputId": "8d332e0f-ceb8-4bcc-88d6-51f7549708b2"
      },
      "source": [
        "!pip install pyarabic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfjdSOGPfiLr",
        "outputId": "9a1e6f12-66ce-4e16-c5f5-91bd59741fa7"
      },
      "source": [
        "!pip install farasapy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.7/dist-packages (0.0.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D18-UfPEfiLv",
        "outputId": "53cb3b9a-3d16-4fef-e71c-d2b012c5cc54"
      },
      "source": [
        "!git clone https://github.com/aub-mind/arabert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'arabert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CYAFFPmfiLy",
        "outputId": "df91249b-b35e-4240-d1f3-14a9b8aa57c5"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: demoji in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from demoji) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from demoji) (0.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-oZNdz37fiL0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Huggingface transformers\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "import pandas as p\n",
        "import re\n",
        "import demoji\n",
        "\n",
        "# Then what you need from tensorflow.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense, LSTM, Bidirectional, BatchNormalization, Attention, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import TruncatedNormal, GlorotUniform\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C5DWC4ZVfiL3"
      },
      "source": [
        "def printHistory(history):\n",
        "    for key in history.history:\n",
        "        print(key, ': ', history.history[key][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uQx20vQRfiL6"
      },
      "source": [
        "def jaccardAccuracy(y_true, y_pred):\n",
        "    #print('step 0')\n",
        "    y_pred = tf.cast(y_pred + 0.5, tf.int32)\n",
        "    y_true = tf.cast(y_true , tf.int32)\n",
        "    #print('step 1')\n",
        "    intersiction = tf.bitwise.bitwise_and(y_true, y_pred)\n",
        "    union = tf.bitwise.bitwise_or(y_true, y_pred)\n",
        "    #print('step 2')\n",
        "    num_intersiction = tf.math.reduce_sum(intersiction, axis=1)\n",
        "    num_intersiction = tf.cast(num_intersiction, dtype=tf.float32)\n",
        "    num_union = tf.math.reduce_sum(union, axis=1)\n",
        "    num_union = tf.cast(num_union, dtype=tf.float32)\n",
        "    #print('step 3')\n",
        "\n",
        "    result = tf.reduce_mean(tf.math.divide_no_nan(num_intersiction,num_union))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nSoxLLt2fiL8"
      },
      "source": [
        "def plotHistory(history, plot_type='loss', ylim = [0,1]):\n",
        "    plt.plot(history.history[plot_type], label=plot_type)\n",
        "    plt.plot(history.history['val_'+plot_type], label = 'val_'+plot_type)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(plot_type)\n",
        "    plt.ylim(ylim)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title(plot_type + ' Graph')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dD7ESDtgfiMA"
      },
      "source": [
        "def printEmotionAccuracy(y, y_pred, classes):\n",
        "    for key in classes:\n",
        "        accuracy = (y[:,classes[key]] == y_pred[:,classes[key]]).sum() / y.shape[0] * 100\n",
        "        print(key, ': ', accuracy, '%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Gm982wNfiMC"
      },
      "source": [
        "def printEmotionF1(y, y_pred, classes):\n",
        "    for key in classes:\n",
        "        f1 = f1_score(y[:,classes[key]], y_pred[:,classes[key]])\n",
        "        print(key, ': ', f1*100, '%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lvMN-AJRfiML"
      },
      "source": [
        "def printJaccardAccuracy(y, y_pred):\n",
        "    intersection = np.logical_and(y, y_pred).sum(-1)\n",
        "    union = np.logical_or(y, y_pred).sum(-1)\n",
        "    accuracy = ((intersection / union).sum()) / union.shape[0] * 100\n",
        "    return accuracy\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8xzGap0UfiMM"
      },
      "source": [
        "def data_cleaning(data):\n",
        "    line = \"\"\n",
        "    lines = []\n",
        "    demoji.download_codes()\n",
        "    for index, row in data.iterrows():\n",
        "        line = re.sub(r'#', '', str(row[\"tweet\"]))\n",
        "        line = re.sub(r'https?:\\/\\/.*[\\r\\n]*', 'URL', line)\n",
        "        line = re.sub(\"@[A-Za-z0-9-_]+\", \"@USER\",line)\n",
        "        line = row[\"tweet\"].replace('\\r', ' ')\n",
        "        line = row[\"tweet\"].replace('\\n', ' ')\n",
        "        line = demoji.replace(line, \"\")\n",
        "        lines.append(line)\n",
        "\n",
        "    data[\"cleaned_tweet\"] = lines\n",
        "    del data['tweet']\n",
        "\n",
        "    return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vCCVv_PfiMO",
        "outputId": "808a2cf3-b5de-4fc4-9c57-1393f6b32935"
      },
      "source": [
        "names = [ 'id','tweet','anger','anticipation', 'disgust','fear','joy','love','optimism','pessimism', 'sadness','surprise','trust']\n",
        "\n",
        "data = p.read_csv(\"/content/drive/MyDrive/research/Emotion detection on arabic/SemEval2018-Task1-all-data/Arabic/E-c/2018-E-c-Ar-train.txt\",\n",
        "                  names = names ,\n",
        "                  sep = '\\t',\n",
        "                  lineterminator= '\\n',\n",
        "                  header=0)\n",
        "dev_data = p.read_csv(\"/content/drive/MyDrive/research/Emotion detection on arabic/SemEval2018-Task1-all-data/Arabic/E-c/2018-E-c-Ar-dev.txt\",\n",
        "                      names = names ,\n",
        "                      sep = '\\t',\n",
        "                      lineterminator= '\\n',\n",
        "                      header=0)\n",
        "\n",
        "data = data_cleaning(data)\n",
        "dev_data = data_cleaning(dev_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emoji data ...\n",
            "... OK (Got response in 0.37 seconds)\n",
            "Writing emoji data to /root/.demoji/codes.json ...\n",
            "... OK\n",
            "Downloading emoji data ...\n",
            "... OK (Got response in 0.36 seconds)\n",
            "Writing emoji data to /root/.demoji/codes.json ...\n",
            "... OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIb2FyXYfiMP",
        "outputId": "e2f02fa6-d9f7-4b80-d3c1-6dc4cd96b6b6"
      },
      "source": [
        "num_sample = data.shape[0]\n",
        "label_frequent = data.iloc[:,1:-1].sum().sort_values(ascending=False)\n",
        "print('Number of Train Samples: ', num_sample)\n",
        "print('Emotion Frequent on Train Samples')\n",
        "print(label_frequent)\n",
        "\n",
        "print('#################')\n",
        "dev_num_sample = dev_data.shape[0]\n",
        "dev_label_frequent = dev_data.iloc[:,1:-1].sum().sort_values(ascending=False)\n",
        "print('Number of Valid Samples: ', dev_num_sample)\n",
        "print('Emotion Frequent on Valid Samples')\n",
        "print(dev_label_frequent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Train Samples:  2278\n",
            "Emotion Frequent on Train Samples\n",
            "anger           899\n",
            "sadness         842\n",
            "joy             605\n",
            "love            562\n",
            "optimism        561\n",
            "pessimism       499\n",
            "disgust         433\n",
            "fear            391\n",
            "anticipation    206\n",
            "trust           120\n",
            "surprise         47\n",
            "dtype: int64\n",
            "#################\n",
            "Number of Valid Samples:  585\n",
            "Emotion Frequent on Valid Samples\n",
            "sadness         217\n",
            "anger           215\n",
            "joy             179\n",
            "love            175\n",
            "optimism        169\n",
            "pessimism       125\n",
            "disgust         106\n",
            "fear             94\n",
            "anticipation     57\n",
            "trust            36\n",
            "surprise         13\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHpxltNPfiMQ",
        "outputId": "3ba75df4-73be-4928-ec4c-c2c58df52b55"
      },
      "source": [
        "label_frequent.loc['anger']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "899"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cYxGQm_fiMS",
        "outputId": "4e0bb5b7-7bad-499c-843e-c3497a368e97"
      },
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "\n",
        "data['cleaned_tweet'] = data['cleaned_tweet'].apply(lambda x: arabert_prep.preprocess(x))\n",
        "\n",
        "dev_data['cleaned_tweet'] = dev_data['cleaned_tweet'].apply(lambda x: arabert_prep.preprocess(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-05-08 21:37:11,560 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qytt0dHNfiMT",
        "outputId": "78ebfa44-4c1b-4f5d-ebb0-77068a732083"
      },
      "source": [
        "model_name = 'asafaya/bert-mini-arabic'\n",
        "task_name = 'classification'\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "config.output_hidden_states = True\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "\n",
        "# Load the Transformers BERT model\n",
        "transformer_model = TFBertModel.from_pretrained(model_name, config = config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at asafaya/bert-mini-arabic were not used when initializing TFBertModel: ['mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at asafaya/bert-mini-arabic.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K99mQkI5fiMU",
        "outputId": "9893b0ee-1fbe-46a6-9ef1-d40f5c4ee831"
      },
      "source": [
        "print(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"_name_or_path\": \"asafaya/bert-mini-arabic\",\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.5.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2nm_GuY9fiMV"
      },
      "source": [
        "# Tokenize the input (takes some time)\n",
        "max_length = max(len(x) for x in data['cleaned_tweet'].to_list())\n",
        "x = tokenizer.batch_encode_plus(\n",
        "    batch_text_or_text_pairs=data['cleaned_tweet'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n",
        "\n",
        "dev_x = tokenizer.batch_encode_plus(\n",
        "    batch_text_or_text_pairs=dev_data['cleaned_tweet'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "94rEpbLYfiMV"
      },
      "source": [
        "classes = {\n",
        "    'anger' : 0,\n",
        "    'anticipation' : 1,\n",
        "    'disgust' : 2,\n",
        "    'fear' : 3,\n",
        "    'joy' : 4,\n",
        "    'love' : 5,\n",
        "    'optimism' : 6,\n",
        "    'pessimism' : 7,\n",
        "    'sadness' : 8,\n",
        "    'surprise' : 9,\n",
        "    'trust' : 10,\n",
        "}\n",
        "y = np.zeros((data.shape[0], 11))\n",
        "for key in classes:\n",
        "    y[:,classes[key]] = data.loc[:, key].values\n",
        "\n",
        "dev_y = np.zeros((dev_data.shape[0], 11))\n",
        "for key in classes:\n",
        "    dev_y[:,classes[key]] = dev_data.loc[:, key].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijT4ueHNfiMW"
      },
      "source": [
        "# Use the last hidden state of BERT as word embbeding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6GtGhfPufiMW"
      },
      "source": [
        "class_weights = {}\n",
        "for key in classes:\n",
        "    class_weights[classes[key]] = num_sample / (label_frequent.loc[key])\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fMIJDU6ZfiMX"
      },
      "source": [
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]\n",
        "bert.trainable = False\n",
        "\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "batch_normalization_1 =  BatchNormalization()(bert_model)\n",
        "\n",
        "biLSTM = Bidirectional(LSTM(128, return_sequences=False), merge_mode='concat')(batch_normalization_1)\n",
        "batch_normalization_2 = BatchNormalization()(biLSTM)\n",
        "\n",
        "#biLSTM_2 = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(batch_normalization_2)\n",
        "#batch_normalization_3 = BatchNormalization()(biLSTM_2)\n",
        "\n",
        "dense = Dense(units=256, activation='tanh', kernel_initializer=TruncatedNormal(stddev=config.initializer_range))(batch_normalization_2)\n",
        "batch_normalization_4 = BatchNormalization()(dense)\n",
        "\n",
        "# Then build your model output\n",
        "outputs = Dense(units=11,activation='sigmoid', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='outputs')(batch_normalization_4)\n",
        "\n",
        "\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()\n",
        "\n",
        "# Set an optimizer\n",
        "optimizer = Adam(learning_rate=1e-03)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = [jaccardAccuracy])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y=y,\n",
        "    class_weight=class_weights,\n",
        "    validation_data = ({'input_ids': dev_x['input_ids']},dev_y),\n",
        "    batch_size=16,\n",
        "    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v-I7iu-HfiMX"
      },
      "source": [
        "printHistory(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "suUvyn25fiMY"
      },
      "source": [
        "plotHistory(history, plot_type='loss', ylim = [0,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JYa74hFUfiMY"
      },
      "source": [
        "plotHistory(history, plot_type='jaccardAccuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2rcTZAz_fiMY"
      },
      "source": [
        "y_pred = model.predict({'input_ids': x['input_ids']})\n",
        "y_pred = y_pred >= 0.5\n",
        "print('Emotion Train F1: ')\n",
        "printEmotionF1(y, y_pred, classes)\n",
        "\n",
        "print('###############')\n",
        "\n",
        "dev_y_pred = model.predict({'input_ids': dev_x['input_ids']})\n",
        "dev_y_pred = dev_y_pred >= 0.5\n",
        "print('Emotion Valid F1: ')\n",
        "printEmotionF1(dev_y, dev_y_pred, classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gZorOYAvfiMY"
      },
      "source": [
        "printJaccardAccuracy(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VsAsjPZfiMZ"
      },
      "source": [
        "# Use the last hidden state of BERT as word embbeding with KLDivergence Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nLwmhZvefiMZ"
      },
      "source": [
        "def abs_KL_div(y_true, y_pred):\n",
        "    y_true = tf.clip_by_value(y_true, tf.keras.backend.epsilon(), 100)\n",
        "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 100)\n",
        "    return tf.math.reduce_sum(tf.math.abs( (y_true- y_pred) * (tf.math.log(y_true / y_pred))), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3WSEtYcjfiMa"
      },
      "source": [
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]\n",
        "bert.trainable = False\n",
        "\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "batch_normalization_1 =  BatchNormalization()(bert_model)\n",
        "\n",
        "biLSTM = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(batch_normalization_1)\n",
        "batch_normalization_2 = BatchNormalization()(biLSTM)\n",
        "\n",
        "#biLSTM_2 = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(batch_normalization_2)\n",
        "#batch_normalization_3 = BatchNormalization()(biLSTM_2)\n",
        "\n",
        "#dense = Dense(units=1024, activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range))(batch_normalization_2)\n",
        "#batch_normalization_4 = BatchNormalization()(dense)\n",
        "\n",
        "# Then build your model output\n",
        "outputs = Dense(units=11,activation='sigmoid', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='outputs')(batch_normalization_2)\n",
        "\n",
        "\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()\n",
        "\n",
        "# Set an optimizer\n",
        "optimizer = Adam(learning_rate=5e-04)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = abs_KL_div,\n",
        "    metrics = [jaccardAccuracy])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y=y,\n",
        "    validation_data = ({'input_ids': dev_x['input_ids']},dev_y),\n",
        "    batch_size=32,\n",
        "    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V9937W1gfiMa"
      },
      "source": [
        "printHistory(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CNcClNnEfiMa"
      },
      "source": [
        "plotHistory(history, plot_type='loss', ylim=[0, 70])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zHh1_2a2fiMc"
      },
      "source": [
        "plotHistory(history, plot_type='jaccardAccuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O_b3SNlefiMc"
      },
      "source": [
        "y_pred = model.predict({'input_ids': x['input_ids']})\n",
        "y_pred = y_pred >= 0.5\n",
        "print('Emotion Train F1: ')\n",
        "printEmotionF1(y, y_pred, classes)\n",
        "\n",
        "print('###############')\n",
        "\n",
        "dev_y_pred = model.predict({'input_ids': dev_x['input_ids']})\n",
        "dev_y_pred = dev_y_pred >= 0.5\n",
        "print('Emotion Valid F1: ')\n",
        "printEmotionF1(dev_y, dev_y_pred, classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXsod2oqfiMd"
      },
      "source": [
        "# Use second-to-last hidden state of BERT as word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BY_HkGmJfiMd"
      },
      "source": [
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]\n",
        "bert.trainable = False\n",
        "\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[2][-2]\n",
        "batch_normalization_1 =  BatchNormalization()(bert_model)\n",
        "\n",
        "biLSTM = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(batch_normalization_1)\n",
        "batch_normalization_2 = BatchNormalization()(biLSTM)\n",
        "\n",
        "#biLSTM_2 = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(batch_normalization_2)\n",
        "#batch_normalization_3 = BatchNormalization()(biLSTM_2)\n",
        "\n",
        "#dense = Dense(units=1024, activation='relu', kernel_initializer=TruncatedNormal(stddev=config.initializer_range))(batch_normalization_2)\n",
        "#batch_normalization_4 = BatchNormalization()(dense)\n",
        "\n",
        "# Then build your model output\n",
        "outputs = Dense(units=11,activation='sigmoid', kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='outputs')(batch_normalization_2)\n",
        "\n",
        "\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iZ-XFxmqfiMe"
      },
      "source": [
        "# Set an optimizer\n",
        "optimizer = Adam(learning_rate=5e-05)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = [jaccardAccuracy])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y=y,\n",
        "    validation_data = ({'input_ids': dev_x['input_ids']},dev_y),\n",
        "    batch_size=32,\n",
        "    epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KF7yMKqyfiMf"
      },
      "source": [
        "for key in history.history:\n",
        "    print(key, ': ', history.history[key][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yTZ1bWU0fiMf"
      },
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Loss Graph')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RF9HDxsEfiMg"
      },
      "source": [
        "plt.plot(history.history['jaccardAccuracy'], label='jaccardAccuracy')\n",
        "plt.plot(history.history['val_jaccardAccuracy'], label = 'val_jaccardAccuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Jaccard Accuracy Graph')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLez57kfiMg"
      },
      "source": [
        "# Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W4MY69MFfiMh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "11c1f23a-4e11-40fc-9df7-e5faa265b58a"
      },
      "source": [
        "class AttentionWh(layers.Layer):\n",
        "    def __init__(self, units=256, max_length=1):\n",
        "        super(AttentionWh, self).__init__()\n",
        "        w_init = tf.keras.initializers.GlorotUniform()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(1, 1, units), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        #return tf.tile(self.w, [1,max_length,1])\n",
        "        attention = tf.keras.layers.Attention()([tf.tile(self.w, [1,max_length,1]), inputs])\n",
        "        #return tf.math.reduce_sum(attention, axis = 1)\n",
        "\n",
        "        return attention"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'layers' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc9cc8c708d9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAttentionWh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttentionWh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mw_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlorotUniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         self.w = tf.Variable(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6_Zl_1cAfiMh"
      },
      "source": [
        "class_weights = {}\n",
        "for key in classes:\n",
        "    class_weights[classes[key]] = num_sample / (label_frequent.loc[key])\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0vEBU3CufiMi"
      },
      "source": [
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]\n",
        "bert.trainable = False\n",
        "\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "batch_normalization_1 =  BatchNormalization(name='Bert_normalization')(bert_model)\n",
        "\n",
        "attention = AttentionWh(units = config.hidden_size, max_length=max_length)(batch_normalization_1)\n",
        "batch_normalization_atention = BatchNormalization(name='Attention_normalization')(attention)\n",
        "\n",
        "biLSTM = Bidirectional(GRU(64, dropout=0.2, recurrent_dropout=0.2,return_sequences=False), merge_mode='concat')(batch_normalization_atention)\n",
        "batch_normalization_2 = BatchNormalization()(biLSTM)\n",
        "#biLSTM_dropout = Dropout(0.2, name='biLSTM_dropout')(batch_normalization_2)\n",
        "\n",
        "#attention = AttentionWh(units = 2*512, max_length=max_length)(batch_normalization_2)\n",
        "#batch_normalization_atention = BatchNormalization(name='Attention_normalization')(attention)\n",
        "\n",
        "#biLSTM = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(attention)\n",
        "#batch_normalization_2 = BatchNormalization()(biLSTM)\n",
        "\n",
        "#biLSTM_2 = Bidirectional(LSTM(512, return_sequences=False), merge_mode='concat')(batch_normalization_2)\n",
        "#batch_normalization_3 = BatchNormalization()(biLSTM_2)\n",
        "\n",
        "dense = Dense(units=64, activation='relu', name='Dense')(batch_normalization_2)\n",
        "batch_normalization_4 = BatchNormalization(name='Dense_normalization')(dense)\n",
        "#dropout = Dropout(0.2, name='dropout')(batch_normalization_4)\n",
        "\n",
        "# Then build your model output\n",
        "outputs = Dense(units=11,activation='sigmoid',  name='outputs')(batch_normalization_4)\n",
        "\n",
        "\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()\n",
        "\n",
        "# Set an optimizer\n",
        "optimizer = Adam(learning_rate=1e-03)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = [jaccardAccuracy])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y=y,\n",
        "    validation_data = ({'input_ids': dev_x['input_ids']},dev_y),\n",
        "    class_weight = class_weights,\n",
        "    batch_size=256,\n",
        "    epochs=192)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XivngpkSfiMi"
      },
      "source": [
        "printHistory(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ohZlCrxAfiMj"
      },
      "source": [
        "plotHistory(history, plot_type='loss', ylim=[0, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WCsikTa-fiMk"
      },
      "source": [
        "plotHistory(history, plot_type='jaccardAccuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9SRAeteAfiMk"
      },
      "source": [
        "y_pred = model.predict({'input_ids': x['input_ids']})\n",
        "y_pred = y_pred >= 0.5\n",
        "print('Emotion Train F1: ')\n",
        "printEmotionF1(y, y_pred, classes)\n",
        "\n",
        "print('###############')\n",
        "\n",
        "dev_y_pred = model.predict({'input_ids': dev_x['input_ids']})\n",
        "dev_y_pred = dev_y_pred >= 0.5\n",
        "print('Emotion Valid F1: ')\n",
        "printEmotionF1(dev_y, dev_y_pred, classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l22TSBpbfiMl"
      },
      "source": [
        "# Multi Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWlGBoYDfiMm"
      },
      "source": [
        "class AttentionWh(layers.Layer):\n",
        "    def __init__(self, units=256, max_length=1):\n",
        "        super(AttentionWh, self).__init__()\n",
        "        w_init = tf.keras.initializers.GlorotUniform()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=w_init(shape=(1, 1, units), dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        #return tf.tile(self.w, [1,max_length,1])\n",
        "        attention = tf.keras.layers.Attention()([tf.tile(self.w, [1,max_length,1]), inputs])\n",
        "        #return tf.math.reduce_sum(attention, axis = 1)\n",
        "\n",
        "        return attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ewsduU8fiMm",
        "outputId": "51835a23-536d-4428-d0cd-ff824a53473b"
      },
      "source": [
        "class_weights = {}\n",
        "for key in classes:\n",
        "    class_weights[classes[key]] = num_sample / (label_frequent.loc[key])\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 2.5339265850945494, 1: 11.058252427184467, 2: 5.2609699769053115, 3: 5.826086956521739, 4: 3.765289256198347, 5: 4.05338078291815, 6: 4.0606060606060606, 7: 4.565130260521042, 8: 2.705463182897862, 9: 48.46808510638298, 10: 18.983333333333334}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmjpQRYrfiMm",
        "outputId": "d3d0b7c5-1454-4574-e977-7f6265ca5163"
      },
      "source": [
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]\n",
        "bert.trainable = False\n",
        "\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[0]\n",
        "batch_normalization_1 =  BatchNormalization(name='Bert_normalization')(bert_model)\n",
        "\n",
        "#Bidirectional GRU\n",
        "#biGRU = Bidirectional(GRU(64, return_sequences=True), merge_mode='concat')(batch_normalization_1)\n",
        "#batch_normalization_2 = BatchNormalization()(biGRU)\n",
        "#biLSTM_dropout = Dropout(0.2, name='biLSTM_dropout')(batch_normalization_2)\n",
        "\n",
        "#Attention on each emotion\n",
        "batch_normalization_atention = []\n",
        "for att in range(11):\n",
        "  attention = AttentionWh(units = config.hidden_size, max_length=max_length)(batch_normalization_1)\n",
        "  normalization = BatchNormalization(name='batch_normalization_atention_'+str(att))(attention)\n",
        "  batch_normalization_atention.append(normalization)\n",
        "\n",
        "#Bi GRU on each emotion\n",
        "batch_normalization_GRU = []\n",
        "for att in range(11):\n",
        "  biGRU = Bidirectional(GRU(64, return_sequences=False), merge_mode='concat')(batch_normalization_atention[att])\n",
        "  normalization = BatchNormalization(name='batch_normalization_GRU_'+str(att))(biGRU)\n",
        "  batch_normalization_GRU.append(normalization)\n",
        "\n",
        "#Dense layer on each emotion\n",
        "batch_normalization_dense = []\n",
        "for att in range(11):\n",
        "  dense = Dense(units=256, activation='relu',  name='dense_'+str(att))(batch_normalization_GRU[att])\n",
        "  normalization = BatchNormalization(name='batch_normalization_dense_'+str(att))(dense)\n",
        "  batch_normalization_dense.append(normalization)\n",
        "\n",
        "\n",
        "#output layer on each emotion\n",
        "output = []\n",
        "for att in range(11):\n",
        "  out = Dense(units=1, activation='sigmoid',  name='output_'+str(att))(batch_normalization_dense[att])\n",
        "  output.append(out)\n",
        "\n",
        "#Final output layer\n",
        "outputs = tf.keras.layers.Concatenate(name='outputs')(output)\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()\n",
        "\n",
        "# Set an optimizer\n",
        "optimizer = Adam(learning_rate=5e-03)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = [jaccardAccuracy])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y=y,\n",
        "    validation_data = ({'input_ids': dev_x['input_ids']},dev_y),\n",
        "    class_weight = class_weights,\n",
        "    batch_size=256,\n",
        "    #epochs=192)\n",
        "    epochs=60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 198)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 11548928    input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Bert_normalization (BatchNormal (None, 198, 256)     1024        bert[4][5]                       \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_44 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_45 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_46 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_47 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_48 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_49 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_50 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_51 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_52 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_53 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attention_wh_54 (AttentionWh)   (None, 198, 256)     256         Bert_normalization[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_0  (None, 198, 256)     1024        attention_wh_44[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_1  (None, 198, 256)     1024        attention_wh_45[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_2  (None, 198, 256)     1024        attention_wh_46[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_3  (None, 198, 256)     1024        attention_wh_47[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_4  (None, 198, 256)     1024        attention_wh_48[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_5  (None, 198, 256)     1024        attention_wh_49[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_6  (None, 198, 256)     1024        attention_wh_50[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_7  (None, 198, 256)     1024        attention_wh_51[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_8  (None, 198, 256)     1024        attention_wh_52[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_9  (None, 198, 256)     1024        attention_wh_53[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_atention_10 (None, 198, 256)     1024        attention_wh_54[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_44 (Bidirectional (None, 128)          123648      batch_normalization_atention_0[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_45 (Bidirectional (None, 128)          123648      batch_normalization_atention_1[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_46 (Bidirectional (None, 128)          123648      batch_normalization_atention_2[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_47 (Bidirectional (None, 128)          123648      batch_normalization_atention_3[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_48 (Bidirectional (None, 128)          123648      batch_normalization_atention_4[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_49 (Bidirectional (None, 128)          123648      batch_normalization_atention_5[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_50 (Bidirectional (None, 128)          123648      batch_normalization_atention_6[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_51 (Bidirectional (None, 128)          123648      batch_normalization_atention_7[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_52 (Bidirectional (None, 128)          123648      batch_normalization_atention_8[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_53 (Bidirectional (None, 128)          123648      batch_normalization_atention_9[0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_54 (Bidirectional (None, 128)          123648      batch_normalization_atention_10[0\n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_0 (Batc (None, 128)          512         bidirectional_44[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_1 (Batc (None, 128)          512         bidirectional_45[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_2 (Batc (None, 128)          512         bidirectional_46[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_3 (Batc (None, 128)          512         bidirectional_47[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_4 (Batc (None, 128)          512         bidirectional_48[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_5 (Batc (None, 128)          512         bidirectional_49[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_6 (Batc (None, 128)          512         bidirectional_50[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_7 (Batc (None, 128)          512         bidirectional_51[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_8 (Batc (None, 128)          512         bidirectional_52[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_9 (Batc (None, 128)          512         bidirectional_53[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_GRU_10 (Bat (None, 128)          512         bidirectional_54[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0 (Dense)                 (None, 256)          33024       batch_normalization_GRU_0[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          33024       batch_normalization_GRU_1[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          33024       batch_normalization_GRU_2[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 256)          33024       batch_normalization_GRU_3[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 256)          33024       batch_normalization_GRU_4[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 256)          33024       batch_normalization_GRU_5[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 256)          33024       batch_normalization_GRU_6[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 256)          33024       batch_normalization_GRU_7[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 256)          33024       batch_normalization_GRU_8[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 256)          33024       batch_normalization_GRU_9[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 256)          33024       batch_normalization_GRU_10[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_0 (Ba (None, 256)          1024        dense_0[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_1 (Ba (None, 256)          1024        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_2 (Ba (None, 256)          1024        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_3 (Ba (None, 256)          1024        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_4 (Ba (None, 256)          1024        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_5 (Ba (None, 256)          1024        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_6 (Ba (None, 256)          1024        dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_7 (Ba (None, 256)          1024        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_8 (Ba (None, 256)          1024        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_9 (Ba (None, 256)          1024        dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_dense_10 (B (None, 256)          1024        dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "output_0 (Dense)                (None, 1)            257         batch_normalization_dense_0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_1 (Dense)                (None, 1)            257         batch_normalization_dense_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_2 (Dense)                (None, 1)            257         batch_normalization_dense_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_3 (Dense)                (None, 1)            257         batch_normalization_dense_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_4 (Dense)                (None, 1)            257         batch_normalization_dense_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_5 (Dense)                (None, 1)            257         batch_normalization_dense_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_6 (Dense)                (None, 1)            257         batch_normalization_dense_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_7 (Dense)                (None, 1)            257         batch_normalization_dense_7[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_8 (Dense)                (None, 1)            257         batch_normalization_dense_8[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_9 (Dense)                (None, 1)            257         batch_normalization_dense_9[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "output_10 (Dense)               (None, 1)            257         batch_normalization_dense_10[0][0\n",
            "__________________________________________________________________________________________________\n",
            "outputs (Concatenate)           (None, 11)           0           output_0[0][0]                   \n",
            "                                                                 output_1[0][0]                   \n",
            "                                                                 output_2[0][0]                   \n",
            "                                                                 output_3[0][0]                   \n",
            "                                                                 output_4[0][0]                   \n",
            "                                                                 output_5[0][0]                   \n",
            "                                                                 output_6[0][0]                   \n",
            "                                                                 output_7[0][0]                   \n",
            "                                                                 output_8[0][0]                   \n",
            "                                                                 output_9[0][0]                   \n",
            "                                                                 output_10[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 13,307,147\n",
            "Trainable params: 1,743,627\n",
            "Non-trainable params: 11,563,520\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/60\n",
            "9/9 [==============================] - 50s 2s/step - loss: 3.9910 - jaccardAccuracy: 0.1906 - val_loss: 0.5814 - val_jaccardAccuracy: 0.2407\n",
            "Epoch 2/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 2.2512 - jaccardAccuracy: 0.2158 - val_loss: 0.5120 - val_jaccardAccuracy: 0.1640\n",
            "Epoch 3/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 1.8429 - jaccardAccuracy: 0.2436 - val_loss: 0.4907 - val_jaccardAccuracy: 0.1613\n",
            "Epoch 4/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 1.6457 - jaccardAccuracy: 0.2781 - val_loss: 0.4665 - val_jaccardAccuracy: 0.1094\n",
            "Epoch 5/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 1.5157 - jaccardAccuracy: 0.3327 - val_loss: 0.4588 - val_jaccardAccuracy: 0.1746\n",
            "Epoch 6/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 1.4617 - jaccardAccuracy: 0.3721 - val_loss: 0.4557 - val_jaccardAccuracy: 0.1958\n",
            "Epoch 7/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 1.3764 - jaccardAccuracy: 0.4104 - val_loss: 0.4449 - val_jaccardAccuracy: 0.2226\n",
            "Epoch 8/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 1.3164 - jaccardAccuracy: 0.4399 - val_loss: 0.4417 - val_jaccardAccuracy: 0.2294\n",
            "Epoch 9/60\n",
            "9/9 [==============================] - 7s 836ms/step - loss: 1.2757 - jaccardAccuracy: 0.4568 - val_loss: 0.4460 - val_jaccardAccuracy: 0.1926\n",
            "Epoch 10/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 1.2106 - jaccardAccuracy: 0.4752 - val_loss: 0.4422 - val_jaccardAccuracy: 0.1927\n",
            "Epoch 11/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 1.1168 - jaccardAccuracy: 0.5156 - val_loss: 0.4492 - val_jaccardAccuracy: 0.1886\n",
            "Epoch 12/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 1.0599 - jaccardAccuracy: 0.5416 - val_loss: 0.4842 - val_jaccardAccuracy: 0.1724\n",
            "Epoch 13/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 1.0220 - jaccardAccuracy: 0.5605 - val_loss: 0.4882 - val_jaccardAccuracy: 0.1680\n",
            "Epoch 14/60\n",
            "9/9 [==============================] - 7s 832ms/step - loss: 0.9840 - jaccardAccuracy: 0.5765 - val_loss: 0.5023 - val_jaccardAccuracy: 0.2103\n",
            "Epoch 15/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.8752 - jaccardAccuracy: 0.6163 - val_loss: 0.4955 - val_jaccardAccuracy: 0.2168\n",
            "Epoch 16/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.8475 - jaccardAccuracy: 0.6425 - val_loss: 0.4995 - val_jaccardAccuracy: 0.2351\n",
            "Epoch 17/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.7944 - jaccardAccuracy: 0.6613 - val_loss: 0.4956 - val_jaccardAccuracy: 0.2231\n",
            "Epoch 18/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.7450 - jaccardAccuracy: 0.6799 - val_loss: 0.5088 - val_jaccardAccuracy: 0.2243\n",
            "Epoch 19/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.7126 - jaccardAccuracy: 0.7029 - val_loss: 0.5156 - val_jaccardAccuracy: 0.2253\n",
            "Epoch 20/60\n",
            "9/9 [==============================] - 7s 836ms/step - loss: 0.6804 - jaccardAccuracy: 0.7076 - val_loss: 0.5140 - val_jaccardAccuracy: 0.2568\n",
            "Epoch 21/60\n",
            "9/9 [==============================] - 7s 836ms/step - loss: 0.6206 - jaccardAccuracy: 0.7415 - val_loss: 0.5508 - val_jaccardAccuracy: 0.2910\n",
            "Epoch 22/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.5990 - jaccardAccuracy: 0.7468 - val_loss: 0.5494 - val_jaccardAccuracy: 0.2752\n",
            "Epoch 23/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.5618 - jaccardAccuracy: 0.7694 - val_loss: 0.5839 - val_jaccardAccuracy: 0.2653\n",
            "Epoch 24/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.5499 - jaccardAccuracy: 0.7640 - val_loss: 0.5833 - val_jaccardAccuracy: 0.2949\n",
            "Epoch 25/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.5314 - jaccardAccuracy: 0.7784 - val_loss: 0.6299 - val_jaccardAccuracy: 0.2752\n",
            "Epoch 26/60\n",
            "9/9 [==============================] - 7s 831ms/step - loss: 0.5154 - jaccardAccuracy: 0.7788 - val_loss: 0.6480 - val_jaccardAccuracy: 0.2740\n",
            "Epoch 27/60\n",
            "9/9 [==============================] - 7s 832ms/step - loss: 0.4953 - jaccardAccuracy: 0.7856 - val_loss: 0.6555 - val_jaccardAccuracy: 0.3069\n",
            "Epoch 28/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.4724 - jaccardAccuracy: 0.8022 - val_loss: 0.6335 - val_jaccardAccuracy: 0.2939\n",
            "Epoch 29/60\n",
            "9/9 [==============================] - 7s 836ms/step - loss: 0.4530 - jaccardAccuracy: 0.8201 - val_loss: 0.6339 - val_jaccardAccuracy: 0.3102\n",
            "Epoch 30/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.4537 - jaccardAccuracy: 0.8131 - val_loss: 0.6458 - val_jaccardAccuracy: 0.3079\n",
            "Epoch 31/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.4358 - jaccardAccuracy: 0.8181 - val_loss: 0.6565 - val_jaccardAccuracy: 0.3303\n",
            "Epoch 32/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.4361 - jaccardAccuracy: 0.8202 - val_loss: 0.6852 - val_jaccardAccuracy: 0.3155\n",
            "Epoch 33/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.4182 - jaccardAccuracy: 0.8300 - val_loss: 0.6890 - val_jaccardAccuracy: 0.3262\n",
            "Epoch 34/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.4431 - jaccardAccuracy: 0.8165 - val_loss: 0.6977 - val_jaccardAccuracy: 0.3463\n",
            "Epoch 35/60\n",
            "9/9 [==============================] - 7s 832ms/step - loss: 0.3972 - jaccardAccuracy: 0.8443 - val_loss: 0.7016 - val_jaccardAccuracy: 0.3369\n",
            "Epoch 36/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.3863 - jaccardAccuracy: 0.8394 - val_loss: 0.7042 - val_jaccardAccuracy: 0.3320\n",
            "Epoch 37/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.3654 - jaccardAccuracy: 0.8553 - val_loss: 0.7431 - val_jaccardAccuracy: 0.3139\n",
            "Epoch 38/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.3876 - jaccardAccuracy: 0.8472 - val_loss: 0.7470 - val_jaccardAccuracy: 0.3505\n",
            "Epoch 39/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.3567 - jaccardAccuracy: 0.8533 - val_loss: 0.7715 - val_jaccardAccuracy: 0.3308\n",
            "Epoch 40/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.3525 - jaccardAccuracy: 0.8553 - val_loss: 0.7935 - val_jaccardAccuracy: 0.3226\n",
            "Epoch 41/60\n",
            "9/9 [==============================] - 7s 837ms/step - loss: 0.3268 - jaccardAccuracy: 0.8681 - val_loss: 0.7598 - val_jaccardAccuracy: 0.3154\n",
            "Epoch 42/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.3485 - jaccardAccuracy: 0.8527 - val_loss: 0.7798 - val_jaccardAccuracy: 0.3397\n",
            "Epoch 43/60\n",
            "9/9 [==============================] - 7s 832ms/step - loss: 0.3191 - jaccardAccuracy: 0.8697 - val_loss: 0.7982 - val_jaccardAccuracy: 0.3104\n",
            "Epoch 44/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.3163 - jaccardAccuracy: 0.8656 - val_loss: 0.7952 - val_jaccardAccuracy: 0.3479\n",
            "Epoch 45/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.3243 - jaccardAccuracy: 0.8655 - val_loss: 0.7955 - val_jaccardAccuracy: 0.3501\n",
            "Epoch 46/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.2868 - jaccardAccuracy: 0.8817 - val_loss: 0.7889 - val_jaccardAccuracy: 0.3258\n",
            "Epoch 47/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.2930 - jaccardAccuracy: 0.8722 - val_loss: 0.8210 - val_jaccardAccuracy: 0.3362\n",
            "Epoch 48/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.3045 - jaccardAccuracy: 0.8711 - val_loss: 0.8297 - val_jaccardAccuracy: 0.3386\n",
            "Epoch 49/60\n",
            "9/9 [==============================] - 7s 837ms/step - loss: 0.2647 - jaccardAccuracy: 0.8912 - val_loss: 0.8086 - val_jaccardAccuracy: 0.3530\n",
            "Epoch 50/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.2750 - jaccardAccuracy: 0.8846 - val_loss: 0.8272 - val_jaccardAccuracy: 0.3623\n",
            "Epoch 51/60\n",
            "9/9 [==============================] - 7s 832ms/step - loss: 0.2588 - jaccardAccuracy: 0.8852 - val_loss: 0.8391 - val_jaccardAccuracy: 0.3689\n",
            "Epoch 52/60\n",
            "9/9 [==============================] - 7s 832ms/step - loss: 0.2535 - jaccardAccuracy: 0.8905 - val_loss: 0.8207 - val_jaccardAccuracy: 0.3431\n",
            "Epoch 53/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.2664 - jaccardAccuracy: 0.8858 - val_loss: 0.8324 - val_jaccardAccuracy: 0.3324\n",
            "Epoch 54/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.2604 - jaccardAccuracy: 0.8839 - val_loss: 0.8486 - val_jaccardAccuracy: 0.3381\n",
            "Epoch 55/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.2433 - jaccardAccuracy: 0.8897 - val_loss: 0.8409 - val_jaccardAccuracy: 0.3514\n",
            "Epoch 56/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.2471 - jaccardAccuracy: 0.8826 - val_loss: 0.8503 - val_jaccardAccuracy: 0.3371\n",
            "Epoch 57/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.2350 - jaccardAccuracy: 0.8902 - val_loss: 0.8352 - val_jaccardAccuracy: 0.3497\n",
            "Epoch 58/60\n",
            "9/9 [==============================] - 7s 834ms/step - loss: 0.2207 - jaccardAccuracy: 0.8971 - val_loss: 0.8423 - val_jaccardAccuracy: 0.3531\n",
            "Epoch 59/60\n",
            "9/9 [==============================] - 7s 833ms/step - loss: 0.2083 - jaccardAccuracy: 0.9015 - val_loss: 0.8514 - val_jaccardAccuracy: 0.3533\n",
            "Epoch 60/60\n",
            "9/9 [==============================] - 7s 835ms/step - loss: 0.2092 - jaccardAccuracy: 0.9105 - val_loss: 0.8652 - val_jaccardAccuracy: 0.3470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbbAfhEohr6D",
        "outputId": "32eac0d6-86d5-472d-b37e-8460fd7c3dcd"
      },
      "source": [
        "printHistory(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss :  0.5505300760269165\n",
            "jaccardAccuracy :  0.7666073441505432\n",
            "val_loss :  0.4848020374774933\n",
            "val_jaccardAccuracy :  0.3229770362377167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Up99mq8zi7Ah",
        "outputId": "e1467ed3-9b80-4210-a7ad-7cf82c5094c5"
      },
      "source": [
        "plotHistory(history, plot_type='loss', ylim=[0, 3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "b6ljV5OejRbf",
        "outputId": "7754f996-a957-4d2c-eaaa-4624b755604c"
      },
      "source": [
        "plotHistory(history, plot_type='jaccardAccuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_3-9W1ojT7H",
        "outputId": "1beef548-2f6b-494c-e286-dba8148fc9b0"
      },
      "source": [
        "y_pred = model.predict({'input_ids': x['input_ids']})\n",
        "y_pred = y_pred >= 0.5\n",
        "print('Emotion Train F1: ')\n",
        "printEmotionF1(y, y_pred, classes)\n",
        "\n",
        "print('###############')\n",
        "\n",
        "dev_y_pred = model.predict({'input_ids': dev_x['input_ids']})\n",
        "dev_y_pred = dev_y_pred >= 0.5\n",
        "print('Emotion Valid F1: ')\n",
        "printEmotionF1(dev_y, dev_y_pred, classes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emotion Train F1: \n",
            "anger :  91.87319884726224 %\n",
            "anticipation :  64.02640264026402 %\n",
            "disgust :  90.54224464060529 %\n",
            "fear :  91.86206896551725 %\n",
            "joy :  95.35080304311073 %\n",
            "love :  94.4922547332186 %\n",
            "optimism :  92.10754553339115 %\n",
            "pessimism :  67.98418972332017 %\n",
            "sadness :  93.58128374325135 %\n",
            "surprise :  88.0952380952381 %\n",
            "trust :  85.71428571428571 %\n",
            "###############\n",
            "Emotion Valid F1: \n",
            "anger :  62.679425837320565 %\n",
            "anticipation :  0.0 %\n",
            "disgust :  24.113475177304963 %\n",
            "fear :  44.5945945945946 %\n",
            "joy :  62.30529595015576 %\n",
            "love :  62.06896551724138 %\n",
            "optimism :  57.14285714285715 %\n",
            "pessimism :  11.188811188811187 %\n",
            "sadness :  51.85185185185185 %\n",
            "surprise :  14.285714285714288 %\n",
            "trust :  0.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjJGZ2jqlo8X"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9zhd3tu2YtF"
      },
      "source": [
        "tweets = model.predict({'input_ids': x['input_ids']})\n",
        "dev_tweets = model.predict({'input_ids': dev_x['input_ids']})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "P1JGBerivMqv",
        "outputId": "6e9df5a5-6d0c-4798-d5dc-f3a67a3fcb90"
      },
      "source": [
        "svm = SVC(decision_function_shape='ovo')\n",
        "svm = svm.fit(tweets, y, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-816310ebd5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SVC' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiXL_A1v4j1I",
        "outputId": "dfca5df3-2e20-4498-8378-cb8bcc6544bc"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "emotion_svm = []\n",
        "for k in range(11):\n",
        "  svm = SVC()\n",
        "  svm = svm.fit(tweets, y[:, k], verbose=True)\n",
        "  emotion_svm.append(svm)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_SRed3q4joy",
        "outputId": "f4251d29-5ff6-466f-e3c1-addddcdb2718"
      },
      "source": [
        "y_pred = np.zeros(y.shape)\n",
        "for k in range(11):\n",
        "  print(emotion_svm[k].predict(tweets).sum())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXtA0DRM8CUY",
        "outputId": "c563adbb-cb25-41cc-c9e1-a468051c2433"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2278, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a-x92br8CFL"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3YEgj1i2dBI",
        "outputId": "98b50d2e-9221-40cd-b962-1e98670e61cb"
      },
      "source": [
        "printJaccardAccuracy(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korIGqHF2YmK"
      },
      "source": [
        "y_pred = model.predict({'input_ids': x['input_ids']})\n",
        "y_pred = y_pred >= 0.5\n",
        "print('Emotion Train F1: ')\n",
        "printEmotionF1(y, y_pred, classes)\n",
        "\n",
        "print('###############')\n",
        "\n",
        "dev_y_pred = model.predict({'input_ids': dev_x['input_ids']})\n",
        "dev_y_pred = dev_y_pred >= 0.5\n",
        "print('Emotion Valid F1: ')\n",
        "printEmotionF1(dev_y, dev_y_pred, classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}